
# üõ°Ô∏è Tutoriel : D√©ployer un SOC "Ready-to-Use" avec Elastic Stack 8.x & Docker

## üéØ Objectif

D√©ployer en quelques minutes une infrastructure de Security Operation Center (SOC) capable de collecter, analyser et visualiser des logs en temps r√©el.

Le d√©fi technique : Ce guide contourne la complexit√© de la s√©curit√© native d'Elastic 8.x (qui interdit d√©sormais l'usage du compte elastic pour Kibana) en impl√©mentant l'authentification moderne par Service Account Token.

## üèóÔ∏è Architecture

-   **Elasticsearch 8.11** : Stockage et indexation.
    
-   **Logstash** : Pipeline d'ingestion universel (TCP & Beats).
    
-   **Kibana** : Interface SIEM pour l'investigation.
    
-   **Docker** : Conteneurisation compl√®te.
    

----------

## ‚ö° √âtape 1 : Pr√©paration de l'environnement (Setup Rapide)

Nous allons cr√©er l'arborescence et g√©n√©rer les fichiers de configuration Logstash en une seule commande pour √©viter les erreurs de montage (Read-Only) classiques sous Docker.

**Copiez-collez ce bloc dans votre terminal :**

Bash

```
# 1. Cr√©ation de l'arborescence
mkdir -p ~/soc-elk/logstash/config
mkdir -p ~/soc-elk/logstash/pipeline
mkdir -p ~/soc-elk/filebeat

# 2. Config Syst√®me Logstash (Fix obligatoire pour Docker)
cat <<EOF > ~/soc-elk/logstash/config/logstash.yml
http.host: "0.0.0.0"
xpack.monitoring.elasticsearch.hosts: [ "http://elasticsearch:9200" ]
EOF

# 3. Pipeline d'ingestion (Port 5000 pour tests, 5044 pour Agents)
cat <<EOF > ~/soc-elk/logstash/pipeline/logstash.conf
input {
  tcp {
    port => 5000
    codec => json_lines
  }
  beats {
    port => 5044
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    user => "elastic"
    password => "MonSuperMotDePasse123!"
    index => "logstash-%{+YYYY.MM.dd}"
  }
  stdout { codec => rubydebug }
}
EOF

# 4. Cr√©ation du fichier Docker Compose vide
touch ~/soc-elk/docker-compose.yml

# 5. Acc√®s au dossier
cd ~/soc-elk

echo "‚úÖ Environnement pr√™t ! Passons √† la configuration Docker."

```

----------

## üê≥ √âtape 2 : Le Manifeste Docker Compose

Ouvrez le fichier `docker-compose.yml` (`nano docker-compose.yml`) et collez la configuration suivante.

**Points cl√©s de cette config :**

1.  **S√©curit√©** : Utilisation de `ELASTICSEARCH_SERVICEACCOUNTTOKEN` au lieu de `USERNAME` pour Kibana.
    
2.  **Stabilit√©** : Montage des volumes Logstash en mode `rw` (lecture-√©criture).
    

YAML

```
version: '3.7'

services:
  # --- ELASTICSEARCH ---
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.1
    container_name: soc-elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=false # D√©sactiv√© pour simplifier le lab local
      - ELASTIC_PASSWORD=MonSuperMotDePasse123!
    ports:
      - "9200:9200"
    networks:
      - elk

  # --- LOGSTASH ---
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.1
    container_name: soc-logstash
    volumes:
      # Mode RW indispensable pour l'init de Logstash
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:rw
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
    ports:
      - "5044:5044"
      - "5000:5000"
    depends_on:
      - elasticsearch
    networks:
      - elk

  # --- KIBANA ---
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.1
    container_name: soc-kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      # ‚ö†Ô∏è C'est ici que la magie op√®re : Token au lieu du user root
      - ELASTICSEARCH_SERVICEACCOUNTTOKEN=${KIBANA_TOKEN}
      # Cl√©s de chiffrement (Obligatoires depuis la v8)
      - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=dzhwrt74f6859g9d5746367859g9d574
      - XPACK_REPORTING_ENCRYPTIONKEY=dzhwrt74f6859g9d5746367859g9d574
      - XPACK_SECURITY_ENCRYPTIONKEY=dzhwrt74f6859g9d5746367859g9d574
    networks:
      - elk

networks:
  elk:
    driver: bridge

```

----------

## üöÄ √âtape 3 : D√©ploiement et S√©curit√©

Pour que Kibana puisse d√©marrer, nous devons g√©n√©rer un jeton de confiance valide aupr√®s d'Elasticsearch.

1.  **D√©marrer la base de donn√©es uniquement :**
    
    Bash
    
    ```
    docker-compose up -d elasticsearch
    
    ```
    
    _(Attendre 30 secondes que le statut passe √† "healthy" ou actif)_
    
2.  G√©n√©rer le Token de Service :
    
    Ex√©cutez cette commande pour cr√©er le lien s√©curis√© :
    
    Bash
    
    ```
    docker exec -it soc-elasticsearch /usr/share/elasticsearch/bin/elasticsearch-service-tokens create elastic/kibana kibana-token
    
    ```
    
    üëâ **Copiez la cha√Æne de caract√®res retourn√©e.**
    
3.  Lancer la stack compl√®te :
    
    Remplacez <VOTRE_TOKEN> par la cha√Æne copi√©e :
    
    Bash
    
    ```
    export KIBANA_TOKEN="<VOTRE_TOKEN>"
    docker-compose up -d
    
    ```
    

----------

## üß™ √âtape 4 : Validation du SOC (Le "Smoke Test")

Une infrastructure sans donn√©es ne sert √† rien. Voici comment valider le flux de bout en bout.

### 1. Le "Ping" Logistique

Simulons une application envoyant un log critique via le r√©seau.

Depuis votre terminal :

Bash

```
echo '{"app": "SOC-Test", "message": "Flux de donn√©es op√©rationnel", "level": "INFO"}' | nc localhost 5000

```

_Si la commande passe sans erreur, le port 5000 est ouvert et Logstash √©coute._

### 2. Configuration de la Vue dans Kibana

1.  Allez sur **[http://localhost:5601](https://www.google.com/search?q=http://localhost:5601)**
    
    -   User : `elastic`
        
    -   Pass : `MonSuperMotDePasse123!`
        
2.  Menu **‚ò∞** > **Stack Management** > **Data Views**.
    
3.  Cliquez sur **Create data view**.
    
4.  Nom : `logstash-*` (Kibana doit trouver l'index cr√©√© par notre test pr√©c√©dent).
    
5.  Timestamp : S√©lectionnez `@timestamp`.
    

### 3. Visualisation (Attention au pi√®ge !)

1.  Allez dans le menu **Discover**.
    
2.  ‚ö†Ô∏è Important : Par d√©faut, Kibana affiche les "Last 15 minutes".
    
    üëâ Changez la p√©riode (en haut √† droite) sur "Today".
    
3.  Vous verrez appara√Ætre votre log de test :
    
    -   `message`: "Flux de donn√©es op√©rationnel"
        

----------

## üîÆ Bonus : Aller plus loin (Vrais Logs)

Votre SOC est pr√™t. Pour ing√©rer de vrais logs (SSH, Syst√®me), il suffit d'ajouter le conteneur **Filebeat** au `docker-compose.yml` :

YAML

```
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.1
    user: root
    volumes:
      - /var/log:/var/log:ro            # Lecture des logs h√¥te
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: filebeat -e -E output.elasticsearch.enabled=false -E output.logstash.hosts=['logstash:5044']
    depends_on:
      - logstash
    networks:
      - elk

```

